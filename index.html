<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sarath Chandra | Computer Vision & AI</title>
    <style>
        /* --- 1. CORE STYLING --- */
        :root {
            --primary: #2563eb;
            --dark: #0f172a;
            --light: #f8fafc;
            --accent: #38bdf8;
        }
        body { font-family: 'Segoe UI', sans-serif; margin: 0; background: var(--light); color: #333; }
        
        /* --- 2. HEADER --- */
        header { background: var(--dark); color: white; padding: 40px 20px; text-align: center; }
        h1 { margin: 0; }
        .tabs { margin-top: 20px; display: flex; justify-content: center; gap: 20px; }
        .tab-btn {
            background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2);
            color: white; padding: 10px 25px; cursor: pointer; border-radius: 20px;
            font-weight: bold; transition: 0.3s;
        }
        .tab-btn:hover, .tab-btn.active { background: var(--primary); border-color: var(--primary); }

        /* --- 3. CONTAINER --- */
        .container { max-width: 1000px; margin: 40px auto; padding: 0 20px; }
        .section { display: none; animation: fadeIn 0.5s; }
        .section.active { display: block; }
        @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }

        /* --- 4. CARD STYLES (Research & Projects) --- */
        .card {
            background: white; border-radius: 12px; overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05); margin-bottom: 30px;
            border-left: 5px solid var(--primary);
        }
        .card-header {
            padding: 20px; cursor: pointer; display: flex; justify-content: space-between; align-items: center;
        }
        .card-header:hover { background: #f1f5f9; }
        .card-title { font-size: 1.4rem; font-weight: bold; margin: 0; }
        .card-tags span {
            font-size: 0.8rem; background: #e0f2fe; color: #0284c7;
            padding: 4px 10px; border-radius: 12px; margin-left: 5px;
        }
        
        /* --- 5. EXPANDABLE CONTENT (Video + Text) --- */
        .card-body {
            display: none; padding: 25px; border-top: 1px solid #eee; background: #fafafa;
        }
        .card.open .card-body { display: block; }
        .video-container {
            width: 100%; height: 400px; background: black; border-radius: 8px;
            display: flex; align-items: center; justify-content: center; color: white;
            margin-bottom: 20px;
        }
        video { width: 100%; height: 100%; object-fit: cover; border-radius: 8px; }
    </style>
</head>
<body>

    <header>
        <h1>Sarath Chandra</h1>
        <p>Computer Vision Researcher | Applied AI Engineer</p>
        
        <div class="tabs">
            <button class="tab-btn active" onclick="switchTab('research')">üî¨ Research</button>
            <button class="tab-btn" onclick="switchTab('projects')">üöÄ Projects</button>
        </div>
    </header>

    <div class="container">
        
        <div id="research-section" class="section active">
            </div>

        <div id="projects-section" class="section">
            </div>

    </div>

    <script>
        // =======================================================
        // üîß DATA SECTION - UPDATED FOR .JPEG
        // =======================================================

        const researchData = [
            {
                title: "Anomaly Detection: Pickpocketing",
                tags: ["Computer Vision", "Decision Fusion", "Optical Flow"],
                mediaUrl: "videos/pickpocketing.mp4", 
                mediaType: "video",
                description: `
                    <p><strong>Goal:</strong> Detect subtle theft actions in crowded surveillance feeds.</p>
                    <p>I developed a fusion model that analyzes two distinct streams:</p>
                    <ul>
                        <li><strong>Spatial Stream:</strong> Detects close proximity between people (using YOLO).</li>
                        <li><strong>Temporal Stream:</strong> Analyzes rapid hand movements using Optical Flow vectors.</li>
                    </ul>
                    <p>The system triggers an alert only when "high proximity" AND "rapid localized motion" occur simultaneously.</p>
                `
            },
            {
                title: "Anomaly Detection: Abandoned Bag",
                tags: ["Object Tracking", "DeepSORT", "YOLOv8"],
                mediaUrl: "videos/bag.mp4",
                mediaType: "video",
                description: `
                    <p><strong>Goal:</strong> Identify luggage left unattended in public spaces.</p>
                    <p>The system assigns a unique ID to every person and object. It calculates the Euclidean distance between a bag and its "owner" over time. If the distance exceeds 3 meters for >30 seconds, the bag is flagged as abandoned.</p>
                `
            }
        ];

        const projectData = [
            {
                title: "Urban Sound Classification & Enhancement",
                tags: ["Audio Processing", "PCEN", "SepFormer", "XGBoost"],
                mediaUrl: "", 
                mediaType: "none", // Keeps it hidden until you have a video
                description: `
                    <p>Built a pipeline to classify safety-critical sounds (gunshots, sirens) in noisy city environments.</p>
                    <ul>
                        <li><strong>Enhancement:</strong> Used PCEN to reduce background city rumble and boost event amplitude.</li>
                        <li><strong>Separation:</strong> Applied SepFormer to isolate human voice from event sounds.</li>
                        <li><strong>Result:</strong> Improved classification accuracy by 15% on the UrbanSound8K dataset.</li>
                    </ul>
                    <p><em>(Demo video coming soon)</em></p>
                `
            },
            {
                title: "License Plate Recognition (LPR)",
                tags: ["Edge AI", "OCR", "React UI"],
                mediaUrl: "images/lpr_demo.jpeg", // UPDATED: Now looks for .jpeg
                mediaType: "image",
                description: `
                    <p>A real-time LPR system designed for edge deployment. It uses a lightweight detection model to crop plates and passes them to an OCR engine for text extraction. Achieved 94% accuracy in variable lighting conditions.</p>
                `
            }
        ];

        // =======================================================
        // ‚öôÔ∏è RENDER LOGIC
        // =======================================================

        function renderMedia(item) {
            // 1. If no media, return empty string
            if (item.mediaType === 'none' || !item.mediaUrl) {
                return ''; 
            }
            
            // 2. If Image
            if (item.mediaType === 'image') {
                return `<div class="video-container" style="background: white;">
                            <img src="${item.mediaUrl}" style="width: 100%; height: 100%; object-fit: contain;" alt="${item.title}">
                        </div>`;
            }

            // 3. If Video (YouTube or Local MP4)
            if (item.mediaUrl.includes('youtube')) {
                return `<div class="video-container">
                            <iframe width="100%" height="100%" src="${item.mediaUrl}" frameborder="0" allowfullscreen></iframe>
                        </div>`;
            } else {
                return `<div class="video-container">
                            <video controls><source src="${item.mediaUrl}" type="video/mp4">Video not found.</video>
                        </div>`;
            }
        }

        function renderCards(data, containerId) {
            const container = document.getElementById(containerId);
            container.innerHTML = data.map((item) => `
                <div class="card" onclick="toggleCard(this)">
                    <div class="card-header">
                        <div class="card-title">
                            <h3>${item.title}</h3>
                            <div class="card-tags">
                                ${item.tags.map(tag => `<span>${tag}</span>`).join('')}
                            </div>
                        </div>
                        <div style="color: #cbd5e1;">‚ñº</div>
                    </div>
                    <div class="card-body">
                        ${renderMedia(item)}
                        <div>${item.description}</div>
                    </div>
                </div>
            `).join('');
        }

        function toggleCard(card) {
            const siblings = card.parentElement.children;
            for (let sibling of siblings) {
                if (sibling !== card) sibling.classList.remove('open');
            }
            card.classList.toggle('open');
        }

        function switchTab(tabName) {
            document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            document.querySelectorAll('.section').forEach(sec => sec.classList.remove('active'));
            document.getElementById(tabName + '-section').classList.add('active');
        }

        // Initialize the view
        renderCards(researchData, 'research-section');
        renderCards(projectData, 'projects-section');

    </script>
</body>
</html>